{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1862e1ca",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1862e1ca",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "source": [
    "# Road Damage Model Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf5152",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b7bf5152",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "source": [
    "### An Image Segmentation Project Using FastAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd06c9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:50.127172Z",
     "start_time": "2022-03-08T22:29:47.424126Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "6cd06c9f",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# !pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "# fastai library doesn't just return a string containing the path to the dataset, but a Path object. \n",
    "# is a useful class from the Python 3 standard library that makes accessing files and directories much easier.\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f360ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:50.147334Z",
     "start_time": "2022-03-08T22:29:50.145359Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "3f360ccc",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "path= Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121d397d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:50.171240Z",
     "start_time": "2022-03-08T22:29:50.168605Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "121d397d",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "# import the image and mask file paths \n",
    "fnames = get_image_files(path/\"empty\")\n",
    "lbl_names = get_image_files(path/'empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43624810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:50.195149Z",
     "start_time": "2022-03-08T22:29:50.191233Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "43624810",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "# goes through the mask files and stores a dictionary with each of the values. In our images we have black and white so\n",
    "# will store two values\n",
    "def n_codes(fnames, is_partial=True):\n",
    "    \"Gather the codes from a list of `fnames`\"\n",
    "    vals = set()\n",
    "    if is_partial:\n",
    "        random.shuffle(fnames) # take a random sample of the mask files\n",
    "        fnames = fnames[:10] # select 10\n",
    "    for fname in fnames:\n",
    "        msk = np.array(PILMask.create(fname)) # creates an array with each of the levels in the png file\n",
    "        for val in np.unique(msk): # find unique values in array (in this case just two values 0 (white) & 255 (black))\n",
    "            if val not in vals:\n",
    "                vals.add(val)\n",
    "    vals = list(vals)\n",
    "    p2c = dict()\n",
    "    for i,val in enumerate(vals):\n",
    "        p2c[i] = vals[i] #unique values are mapped sequentially to numbers starting at 0 -> {0:0, 1: 255}\n",
    "    return p2c\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3473c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:50.217147Z",
     "start_time": "2022-03-08T22:29:50.215060Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "c3473c4e",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "vals = n_codes(lbl_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae736d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:50.240753Z",
     "start_time": "2022-03-08T22:29:50.237939Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "0ae736d7",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "def get_my_y(fname:Path): \n",
    "    fn = path/'mask'/f'{fname.stem}.png'\n",
    "    msk = np.array(PILMask.create(fn))\n",
    "    mx = np.max(msk)\n",
    "    for i, val in enumerate(vals):\n",
    "        msk[msk==vals[i]] = val\n",
    "    return PILMask.create(msk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb2e9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:51.164721Z",
     "start_time": "2022-03-08T22:29:51.162946Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "bdb2e9aa",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "# labels used in datablock\n",
    "codes = ['good', 'damage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92bde2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:29:51.658891Z",
     "start_time": "2022-03-08T22:29:51.653826Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "c92bde2b",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "# Data Block is essentially the equivalent to the pipeline in Scikit Learn.\n",
    "# A DataBlock is just a blue print on how to assemble your data. It does not do anything until you pass it a source. \n",
    "# You can choose to then convert that source into a Datasets or a DataLoaders by using the DataBlock.datasets or \n",
    "# DataBlock.dataloaders method.\n",
    "\n",
    "# To build a DataBlock you need to give the library four things: \n",
    "# the types of your input/labels, and at least two functions: get_items and splitter.\n",
    "\n",
    "\n",
    "ds = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "                   get_items=get_image_files, # where is the data\n",
    "                   splitter=RandomSplitter(), # how to split data. Usually a random split between the training and validation dataset.\n",
    "                   get_y=get_my_y, # what to apply to the outputs\n",
    "                   item_tfms=Resize(224), # item transform applied on an individual item basis. This is done on the CPU.\n",
    "                   batch_tfms=[Normalize.from_stats(*imagenet_stats)]) # is batch transform applied on batches of data. This is done in GPU.\n",
    "\n",
    "# note on batch transformation\n",
    "# .normalize normalises the data. Neural nets want  data to have a mean of zero and a standard deviation of 1. \n",
    "# done by subracting from each score the mean of the variable and then deviding it by the standard deviation of \n",
    "# that variable. \n",
    "# The mean and sd of the imagenet data are stored in the imagenet_stat variable.\n",
    "# (Note that if you use the imagenet pretrained model. You do not want to use the mean and standard \n",
    "# deviations of your data but the mean and standard deviation of the original imagenet data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e8183c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:30:24.933695Z",
     "start_time": "2022-03-08T22:30:24.804697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stuart/Desktop/Data_Projects/road_damage/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eb5096f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:30:18.071322Z",
     "start_time": "2022-03-08T22:30:18.067662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe0efd79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:40:54.343332Z",
     "start_time": "2022-03-08T22:40:54.305320Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "fe0efd79",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:1051: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create the dataloader from the datablock\n",
    "dls = ds.dataloaders(path/'images', bs=1)\n",
    "# bs (int): how many samples per batch to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6698379c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:41:11.276856Z",
     "start_time": "2022-03-08T22:40:55.199130Z"
    },
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "6698379c",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/stuart/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a315b84033f4576afc378a5f2032f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A traditional CNN won't work for segmentation, therfore use a special kind of model called a UNet, \n",
    "# Convolutional neural network; a type of neural network that works particularly well for computer vision tasks\n",
    "# Creating the model setup (not actually fitting it here)\n",
    "learn = unet_learner(dls, resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69d699",
   "metadata": {
    "gradient": {
     "execution_count": 11,
     "id": "da69d699",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": [
    "# # load the model that was saved above\n",
    "# # note that its required that the learn object i.e. the model is created before doing this (this was done above)\n",
    "# learn = learn.load('model_tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580fd781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:41:16.322823Z",
     "start_time": "2022-03-08T22:41:15.987747Z"
    },
    "gradient": {
     "execution_count": 12,
     "id": "580fd781",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "# had to run the following installations in addition to enable opencv-python to run on paperspace\n",
    "# need to run in terminal as can't answer y/n in jupyter\n",
    "\n",
    "# apt-get update\n",
    "# apt-get upgrade\n",
    "# apt install libgl1-mesa-glx\n",
    "# pip install opencv-python \n",
    "import cv2 #import opencv-python (uses the old name still for import)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b53d4",
   "metadata": {
    "gradient": {
     "id": "735b53d4",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "source": [
    "#### Upload Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c6a8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:41:18.525350Z",
     "start_time": "2022-03-08T22:41:18.515134Z"
    },
    "gradient": {
     "execution_count": 13,
     "id": "60c6a8c9",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd4d23032c04380aadba6baa9caf318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_uploaded = widgets.FileUpload()\n",
    "img_uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0abfea96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T22:41:20.916982Z",
     "start_time": "2022-03-08T22:41:20.894451Z"
    },
    "gradient": {
     "execution_count": 15,
     "id": "0abfea96",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8f1ef99aed424e98ecea5549ef0746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Identify Damage', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description='Identify Damage')\n",
    "out = widgets.Output()\n",
    "def on_button_clicked(_):\n",
    "    # \"linking function with output\"\n",
    "    with out:\n",
    "      # what happens when we press the button\n",
    "        pred = learn.predict(img_uploaded.data[-1])\n",
    "        plt.imsave('solution.png', pred[0]) #Save an array as an image file.\n",
    "        img1 = np.array(PILImage.create(img_uploaded.data[-1]))\n",
    "        img2 = cv2.imread('solution.png')\n",
    "        img1=cv2.resize(img1, (224,224))\n",
    "        img2=cv2.resize(img2, (224,224))\n",
    "\n",
    "        result = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)\n",
    "        print('computing...')\n",
    "        plt.imshow(result)\n",
    "\n",
    "\n",
    "        \n",
    "# linking button and function together using a button's method\n",
    "button.on_click(on_button_clicked)\n",
    "# displaying button and its output together\n",
    "widgets.VBox([button,out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b7b64a",
   "metadata": {
    "gradient": {
     "id": "b5b7b64a",
     "kernelId": "c14a4875-ab2b-4e67-a2c4-f1cba211334b"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
